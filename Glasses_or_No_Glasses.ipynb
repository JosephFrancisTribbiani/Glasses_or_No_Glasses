{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Импортируем необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "from torchmetrics.classification.accuracy import Accuracy\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Количество батчей\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Количество эпох\n",
    "EPOCHS = 100\n",
    "\n",
    "# Количество классов\n",
    "OUTPUT_SIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем custom функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WithWithoutSpecs(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        self.annotations = self.join_annotations(csv_file=csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        return\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns len of dataset\n",
    "        \"\"\"\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Specific image and target for this item\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 1])\n",
    "        image = io.imread(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 0]))\n",
    "    \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return (image, y_label)\n",
    "\n",
    "    def join_annotations(self, csv_file):\n",
    "        data = pd.read_csv(csv_file, usecols=['id', 'glasses'])\n",
    "        data['link'] = data['id'].apply(lambda s: 'face-' + str(s) + '.png')\n",
    "        data.drop(['id'], inplace=True, axis=1)\n",
    "        return data\n",
    "\n",
    "\n",
    "def image_shower(images, labels, n=4):\n",
    "    \"\"\"\n",
    "    Данная функция нужна для вывода изображений\n",
    "    \"\"\"\n",
    "    classes = ['without glasses', 'with glasses']\n",
    "    fig, axs = plt.subplots(1, n, constrained_layout=True, figsize=(12, 12))\n",
    "    for i, image in enumerate(images[:n]):\n",
    "        image = image / 2 + 0.5\n",
    "        axs[i].imshow(image.numpy().transpose((1, 2, 0)).squeeze())\n",
    "        axs[i].set_title(classes[labels[i]])\n",
    "        axs[i].axis('off')\n",
    "        \n",
    "\n",
    "def save_to_file(*args):\n",
    "    \"\"\"\n",
    "    Для сохранения значений Loss и Accuracy в файлик\n",
    "    \"\"\"\n",
    "    with open('models/v2/logs.csv', 'a') as f:\n",
    "        f.write(';'.join(map(str, args)) + '\\n')\n",
    "\n",
    "        \n",
    "def run_train():\n",
    "    \"\"\"\n",
    "    Обучение модели\n",
    "    \"\"\"\n",
    "    best_test_loss_value = float('inf')\n",
    "    for epoch in range(EPOCHS): \n",
    "        \n",
    "        # train часть\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        \n",
    "        for features, labels in tqdm(train_loader):\n",
    "            # помещаем данные на GPU\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # сбрасываем накопленный градиент \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # предсказываем\n",
    "            output = model(features)\n",
    "            \n",
    "            # считаем ошибку, точность и градиенты\n",
    "            loss = criterion(output, labels)\n",
    "            loss.backward()\n",
    "            acc = accuracy(output, labels)\n",
    "            \n",
    "            # делаем шаг оптимизатора (обновляем веса)\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc.item())\n",
    "            \n",
    "        train_loss_value = np.mean(running_loss)\n",
    "        train_accuracy_value = np.mean(running_acc)\n",
    "        \n",
    "        # test часть\n",
    "        running_loss = []\n",
    "        running_acc = []\n",
    "        \n",
    "        for features, labels in test_loader:\n",
    "            # помещаем данные на GPU\n",
    "            features, labels = features.to(device), labels.to(device)\n",
    "            \n",
    "            # предсказываем\n",
    "            output = model(features)\n",
    "            \n",
    "            # считаем ошибку и точность\n",
    "            loss = criterion(output, labels)\n",
    "            acc = accuracy(output, labels)\n",
    "\n",
    "            running_loss.append(loss.item())\n",
    "            running_acc.append(acc.item())\n",
    "            \n",
    "        test_loss_value = np.mean(running_loss)\n",
    "        test_accuracy_value = np.mean(running_acc)\n",
    "        \n",
    "        save_to_file(epoch, train_loss_value, train_accuracy_value, test_loss_value, test_accuracy_value)\n",
    "        if test_loss_value < best_test_loss_value:\n",
    "            model_path = os.path.join('models\\\\v2', 'model.pth')\n",
    "            torch.save(model, model_path)\n",
    "            best_test_loss_value = test_loss_value\n",
    "                \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установить GPU как device для вычислений PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим свой датасет с картинками\n",
    "\n",
    "Разобьем его на тренировочную и валидационную выборку\n",
    "\n",
    "Создадим DataLoader для тренировочной и тестовой выборок\n",
    "\n",
    "**Датасет для обучения взят <a href='https://www.kaggle.com/jeffheaton/glasses-or-no-glasses'>отсюда</a>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToPILImage(), \n",
    "     transforms.Resize((64, 64)),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "dataset = WithWithoutSpecs(csv_file='datasets/02/train.csv',\n",
    "                           root_dir='datasets/02/images', transform=transform)\n",
    "train_dataset, test_dataset = random_split(dataset, [4000, 500])\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем несколько изображений, чтобы проверить, правильно ли у нас сформировался DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "image_shower(images, labels, n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим нашу модель\n",
    "\n",
    "Заморозим веса\n",
    "\n",
    "И переопределим последний слой на два класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.require = False\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(512, OUTPUT_SIZE) , nn.Sigmoid())\n",
    "model.to(device);  # переносим нашу модель на GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дообучим сеть на нашем датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "accuracy = Accuracy().to(device)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=0.1, alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Предскажем классы на валидационной выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "# путь к нашей модели, которую мы будем использовать для предсказания\n",
    "PATH_TO_MODEL = 'model.pth'\n",
    "# путь к изображениям, которые необходимо классифицировать\n",
    "PATH_TO_IMAGES = 'images'\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.ToPILImage(), \n",
    "                                transforms.Resize((64, 64)),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])])\n",
    "\n",
    "\n",
    "# загружаем обученную модель\n",
    "model = torch.load(PATH_TO_MODEL)\n",
    "model.eval()\n",
    "\n",
    "for img_name in os.listdir(PATH_TO_IMAGES):\n",
    "    img_path = os.path.join(PATH_TO_IMAGES, img_name)\n",
    "    image = transform(io.imread(img_path)).view(1, 3, 64, 64)\n",
    "    output = model(image)\n",
    "    _, prediction = torch.max(output, 1)\n",
    "    \n",
    "    with open('predictions.csv', 'a') as f:\n",
    "        f.write(img_name + ';' + str(prediction.item()) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Посмотрим на результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('predictions.csv', sep=';', header=None, names=['image', 'prediction'])\n",
    "df.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
